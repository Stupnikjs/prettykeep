{"color":"DEFAULT","isTrashed":false,"isPinned":false,"isArchived":false,"annotations":[{"description":"","source":"WEBLINK","title":"How to code decision tree in Python from scratch - Ander Fernández","url":"https://anderfernandez.com/en/blog/code-decision-tree-python-from-scratch/"}],"textContent":"https://anderfernandez.com/en/blog/code-decision-tree-python-from-scratch/\n\nL'arbre de décision est un algorithme très utilisé en machine learning. \n\nLe principe est de créer une arborescence.\nAvec des branches et des feuilles qui représente la fin de l'arborescence. \nChaque feuille va correspondre à une valeur catégorielle, ou continue à prédire. \n\nLe choix de l'ordre des features s'établit en fonction de l'impureté de la feature par rapport à la valeur cible. La première feature de l'arbre est celle avec l'impureté la plus basse.\n\nL'index de Gini est souvent utilisé pour l'impureté \n\nG = 1 - sum(Pi^2)\n\nPrenons l'exemple d'un tableau \n\nAvec une feature et le label a prédire \n\nLa feature a 6 True et 4 False \n\n\nGini_feat_pos  = 1 - ( (feat_pos_lab_pos / feat_pos) ^ 2 + (feat_pos_lab_neg/ feat_pos) ^ 2 ) \nIdem pour \n\nGini_feat = 6/10 * Gini_feat_pos + 4/10 * Gini_feat_neg ","title":"Arbre de Décision ","userEditedTimestampUsec":1698244220134000,"createdTimestampUsec":1697743417970000,"textContentHtml":"<p dir=\"ltr\" style=\"line-height:1.38;margin-top:0.0pt;margin-bottom:0.0pt;\"><span style=\"font-size:16.0pt;font-family:'Google Sans';color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\">https://anderfernandez.com/en/blog/code-decision-tree-python-from-scratch/<\/span><\/p><br /><p dir=\"ltr\" style=\"line-height:1.38;margin-top:0.0pt;margin-bottom:0.0pt;\"><span style=\"font-size:16.0pt;font-family:'Google Sans';color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\">L'arbre de décision est un algorithme très utilisé en machine learning.&nbsp;<\/span><\/p><br /><p dir=\"ltr\" style=\"line-height:1.38;margin-top:0.0pt;margin-bottom:0.0pt;\"><span style=\"font-size:16.0pt;font-family:'Google Sans';color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\">Le principe est de créer une arborescence.<\/span><\/p><p dir=\"ltr\" style=\"line-height:1.38;margin-top:0.0pt;margin-bottom:0.0pt;\"><span style=\"font-size:16.0pt;font-family:'Google Sans';color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\">Avec des branches et des feuilles qui représente la fin de l'arborescence.&nbsp;<\/span><\/p><p dir=\"ltr\" style=\"line-height:1.38;margin-top:0.0pt;margin-bottom:0.0pt;\"><span style=\"font-size:16.0pt;font-family:'Google Sans';color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\">Chaque feuille va correspondre à une valeur catégorielle, ou continue à prédire.&nbsp;<\/span><\/p><br /><p dir=\"ltr\" style=\"line-height:1.38;margin-top:0.0pt;margin-bottom:0.0pt;\"><span style=\"font-size:16.0pt;font-family:'Google Sans';color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\">Le choix de l'ordre des features s'établit en fonction de l'impureté de la feature par rapport à la valeur cible. La première feature de l'arbre est celle avec l'impureté la plus basse.<\/span><\/p><br /><p dir=\"ltr\" style=\"line-height:1.38;margin-top:0.0pt;margin-bottom:0.0pt;\"><span style=\"font-size:16.0pt;font-family:'Google Sans';color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\">L'index de Gini est souvent utilisé pour l'impureté&nbsp;<\/span><\/p><br /><p dir=\"ltr\" style=\"line-height:1.38;margin-top:0.0pt;margin-bottom:0.0pt;\"><span style=\"font-size:16.0pt;font-family:'Google Sans';color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\">G = 1 - sum(Pi^2)<\/span><\/p><br /><p dir=\"ltr\" style=\"line-height:1.38;margin-top:0.0pt;margin-bottom:0.0pt;\"><span style=\"font-size:16.0pt;font-family:'Google Sans';color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\">Prenons l'exemple d'un tableau&nbsp;<\/span><\/p><br /><p dir=\"ltr\" style=\"line-height:1.38;margin-top:0.0pt;margin-bottom:0.0pt;\"><span style=\"font-size:16.0pt;font-family:'Google Sans';color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\">Avec une feature et le label a prédire&nbsp;<\/span><\/p><br /><p dir=\"ltr\" style=\"line-height:1.38;margin-top:0.0pt;margin-bottom:0.0pt;\"><span style=\"font-size:16.0pt;font-family:'Google Sans';color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\">La feature a 6 True et 4 False&nbsp;<\/span><\/p><br /><br /><p dir=\"ltr\" style=\"line-height:1.38;margin-top:0.0pt;margin-bottom:0.0pt;\"><span style=\"font-size:16.0pt;font-family:'Google Sans';color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\">Gini_feat_pos&nbsp; = 1 - ( (feat_pos_lab_pos / feat_pos) ^ 2 + (feat_pos_lab_neg/ feat_pos) ^ 2 )&nbsp;<\/span><\/p><p dir=\"ltr\" style=\"line-height:1.38;margin-top:0.0pt;margin-bottom:0.0pt;\"><span style=\"font-size:16.0pt;font-family:'Google Sans';color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\">Idem pour&nbsp;<\/span><\/p><br /><p dir=\"ltr\" style=\"line-height:1.38;margin-top:0.0pt;margin-bottom:0.0pt;\"><span style=\"font-size:16.0pt;font-family:'Google Sans';color:#000000;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;\">Gini_feat = 6/10 * Gini_feat_pos + 4/10 * Gini_feat_neg <\/span><\/p>","labels":[{"name":"Machine Learning"}]}